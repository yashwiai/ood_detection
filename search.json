[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OOD Detection",
    "section": "",
    "text": "This library is used for OOD Detection where a model encounters new classes at test time that were not seen during training. The goal is to detect that such inputs do not belong to any of the training classes."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "OOD Detection",
    "section": "Install",
    "text": "Install\npip install ood_detection\nor\nconda install -c yashkhandelwal ood_detection"
  },
  {
    "objectID": "index.html#example-usage",
    "href": "index.html#example-usage",
    "title": "OOD Detection",
    "section": "Example Usage",
    "text": "Example Usage\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs\nfrom ood_detection.core import OODMetric\n\n\n# example dataset\nn_samples = 1000\nn_centers = 10\nn_features = 1024\n\nx, y = make_blobs(n_samples=n_samples, n_features=n_features, centers=n_centers, random_state=0)\n\n\n# using the last 5 cluster as the test and rest as train\ntrain_embedding = x[np.where(y < (n_centers - 5))]\ntrain_labels = y[np.where(y < (n_centers - 5))]\n\ntest_embedding = x[np.where(y >= (n_centers - 5))]\ntest_labels = y[np.where(y >= (n_centers - 5))]\n\n\nood = OODMetric(train_embedding, train_labels)\n\nin_distribution_rmd = ood.compute_rmd(train_embedding)\nood_rmd = ood.compute_rmd(test_embedding)\n\n\nplt.hist([in_distribution_rmd, ood_rmd], label=[\"In Distribution\", \"OOD\"])\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "index.html#built-using-nbdev",
    "href": "index.html#built-using-nbdev",
    "title": "OOD Detection",
    "section": "Built using NBDev",
    "text": "Built using NBDev\nThis OOD Detection library was built in a jupyter notebook with proper documentation and test cases. These test cases are verified before they are published to GitHub Pages, PyPi, Conda, etc.\nI’ve written down a NBDev Tutorial explaining the thought process of Jeremy Howard and the folks at FastAI behind building it. The tutorial covers how to get started, important functions, and a description of those I used with the issues I faced while exploring the tool for the first time."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "OOD Detection",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nSpecial thanks to Yugam Tiwari for explaining the code he has written for the OODMetric and for helping me with packaging the library.\nThanks to Soma Dhavala for coming up with the idea to prepare NBDev Tutorial and helping with the initial reading and exploration material."
  },
  {
    "objectID": "tutorial.html",
    "href": "tutorial.html",
    "title": "NBDev Tutorial",
    "section": "",
    "text": "nbdev is a notebook-driven development platform. Simply write notebooks with lightweight markup and get high-quality documentation, tests, continuous integration, and packaging for free!\nnbdev makes debugging and refactoring your code much easier than in traditional programming environments since you always have live objects at your fingertips. nbdev also promotes software engineering best practices because tests and documentation are first class. In a minute or two, you can provide installable libraries to anyone. Even the smallest of code can be just turned into a library and can be useful for someone.\nTests, docs, and code are part of the same context and are co-located. nbdev not only does make the code more approachable but forcing you to write docs forces you to think more about code."
  },
  {
    "objectID": "tutorial.html#what-you-can-do-using-nbdev",
    "href": "tutorial.html#what-you-can-do-using-nbdev",
    "title": "NBDev Tutorial",
    "section": "What you can do using NBDev",
    "text": "What you can do using NBDev\n\nSearchable hyperlinked documentation - Documentation is generated automatically using quarto and gets hosted on Github pages using the automatic workflows designed when you initialize a repository with nbdev. Documents support LaTeX, are searchable, and also support automatic hyperlinking with other parts of your code.\nTwo-way sync between notebooks and editors - Using simple commands, the notebook prepares the python scripts which you can also edit in your editors like VSCode, and then syncs the notebooks with the new changes.\nPip and Conda installers - Publish packages to PyPI and Conda directly from your notebook code. Creates python modules and provides tools to simplify package releases. Python best practices for releasing packages are automatically followed, which are sometimes very difficult to do manually in dead coding environments.\nTesting - Written as part of the notebook cells along with your main code. Using a single command, nbdev runs all the tests in parallel when you prepare your packages. Having tests as part of your main code makes sure they are updated when changes are made to code and are easily accessible unlike in dead coding environments where they are stored separately and need a lot of contexts switching to understand which test case belongs to which function.\nContinuous Integration - Automatically creates Github Actions workflows that run the tests, rebuild the docs, and host them on Github pages\nGit friendly - Provides Jupyter/Git hooks that cleans unwanted metadata, thus making it easy to compare git diffs. Also, in case of merge conflicts, instead of giving errors like can’t open notebook renders a clean merge conflict in a human-readable format.\nEasy Updates - Your ReadMe, PyPi page, and Conda page always stay updated based on the things you write in index.ipynb."
  },
  {
    "objectID": "tutorial.html#i-like-notebooks---jeremy-howard",
    "href": "tutorial.html#i-like-notebooks---jeremy-howard",
    "title": "NBDev Tutorial",
    "section": "“I Like Notebooks” - Jeremy Howard",
    "text": "“I Like Notebooks” - Jeremy Howard\nFastAI has built a lot of amazing tools just out of notebooks. Most of the libraries are built using nbdev. In one of his videos I Like Notebooks, Jeremy Howard shares why he likes notebooks with proper reasons on how it’s time to start rethinking software engineering principles. He gives some amazing examples of how Jupyter Notebooks coupled with nbdev follows the best practices and are a great way to teach/write technical blogs, share codes, and create reproducible results/issues.\n\n\n\n        \n        \n\n\n\nSummary\n\nLiterate Programming - Literate programming is a methodology that combines a programming language with a documentation language, thereby making programs more robust, more easily maintained, and arguably more fun to write. The main idea is to treat the program as a piece of literature, addressed to human beings rather than to a computer. Notebooks support this by default and act like a journal you can go through from top to bottom, understanding the thought process of the developer along with code and its outputs.\nLess chances of errors - Since you can run a small part of code, see its output, make plots, and visualize images, makes it easy to debug the issues and make sure the inputs are correct. In dead coding environments, there are no ways to visualize the inputs and outputs which often leads to errors.\nEasily sharable - With notebooks, you can easily share the results, and issues with others and they can easily reproduce those using something like a Colab environment. And, the most important thing, you can not only share text but also share images, videos, plots, etc. With Software 2.0 we are not just working with text but have a varied kind of data that needs a lot of exploration.\nTests live along with code - In dead coding environments, it can be very easy to miss out on tests completely. They live separately from the main code. In Nbdev or in general notebooks, the tests live along with the main code.\nBetter suggestions - Jupyter notebooks are more helpful, as they are more correct in suggesting functions. VSCode doesn’t know the output of the previous line, but jupyter knows that as you ran the code.\n\n\n\nExamples\n\nFastAI Documentation - The whole documentation is written out of the notebooks. The good thing about this is, that the documentation and the tests always stay updated with new changes in the library.\nFastpages - Create technical blogs with LaTeX, images, videos, plots, and code snippets directly from your notebooks.\nFastdoc - Create publication-quality books directly from Jupyter Notebooks. The biggest example of this is the book Deep Learning for Coders written completely out of notebooks. This Github repository has the exact notebooks that were used for creating the publication-ready book. The best part of writing a book from a notebook is that the example code you add in your book is actual code, that will run and give the correct output, unlike other books that have many errors or dependency issues. The book is available on Amazon."
  },
  {
    "objectID": "tutorial.html#steps-to-use-nbdev",
    "href": "tutorial.html#steps-to-use-nbdev",
    "title": "NBDev Tutorial",
    "section": "Steps to use NBDev",
    "text": "Steps to use NBDev\n\nInitialize a GitHub repository.\nClone it to the system.\nInstall nbdev using\npip install nbdev\nor\nconda install -c fastai nbdev\nRun nbdev_new command.\n\nInitializes the repository with nbdev environment files and sample jupyter notebooks.\nSetup GitHub actions workflow scripts to test notebooks, and build and deploy Quarto docs to GitHub pages.\nConfigure Quarto for publication-grade technical documentation.\nStreamline publishing Python packages to PyPI and Conda.\n\nRun nbdev_install_hooks\n\nThis provides three hooks to ease Jupyter-git integration.\nnbdev_merge: Handles merge conflicts so that notebook loading error doesn’t pop up.\nnbdev_clean: On saving, cleans up the metadata for clean git commits and pull requests.\nnbdev_trust: Automatically trusts all the notebooks instead of doing them manually every time.\n\nRun nbdev_preview to preview your docs generated using the notebooks. You can see the live changes in the docs when you save the change in the notebooks.\nBefore committing your changes to GitHub, run nbdev_prepare in the terminal, which bundles the following commands:\n\nnbdev_export: Builds the .py modules from Jupyter notebooks\nnbdev_test: Tests your notebooks\nnbdev_clean: Cleans your notebooks to get rid of extraneous output for GitHub\nnbdev_readme: Updates README.md from your index notebook.\n\nYou can run these commands individually also.\nPush to GitHub to see the workflows in action. Essentially two workflows are made as part of CI:\n\nRunning all the tests in your notebook\nBuilding the documentation page and publishing to GitHub pages\n\nSetting up the pip environment for publishing\n\nFor publishing to PyPi, you’ll have to register your account on the account registration page\nInstall twine as that is required for publishing to pip\n\npip install twine\n\nCreate a file ~/.pypirc in the given format\n\n[pypi]\nusername = your_pypi_username\npassword = your_pypi_password\n\nNow you’re all set to publish to your pip account.\n\nSetting up the Conda environment for publishing\n\nSimilar to pip, you’ll have to register your account on the account registration page\nIf you’re using miniconda then anaconda-client won’t be installed. To install that:\n\nconda install conda-build anaconda-client\n\nLogin to anaconda using\n\nanaconda login\n\nApparently, the settings.ini file generated by running nbdev_new doesn’t create the placeholders for Conda variables in the file. You’ll have to add a variable conda_user which can be your username or the organization name. Add conda_user = <username> to the file.\nNow you’re all set to publish to your Conda account.\n\nOnce everything is set, you can push the packages to PyPi or Conda using a simple command nbdev_release_both\n\nTo publish only to PyPi nbdev_pypi\nTo publish only to Conda nbdev_conda\nIf you’ve already pushed the packages, and want to push a new version of it run the same command nbdev_release_both. It will show an error that the following version already exists and then bump the version number set in your settings.ini file. You can bump the version number manually also by making the change in the file. Run nbdev_release_both again and a new version of the library will be published.\n\n\nIf you want to know about other functions, refer to the documentation or can run the nbdev_help command to see the available functions. Here is the output of the command\n\n!nbdev_help\n\nnbdev_bump_version              Increment version in settings.ini by one\nnbdev_changelog                 Create a CHANGELOG.md file from closed and labeled GitHub issues\nnbdev_clean                     Clean all notebooks in `fname` to avoid merge conflicts\nnbdev_conda                     Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it\nnbdev_create_config             Create a config file.\nnbdev_docs                      Create Quarto docs and README.md\nnbdev_export                    Export notebooks in `path` to Python modules\nnbdev_filter                    A notebook filter for Quarto\nnbdev_fix                       Create working notebook from conflicted notebook `nbname`\nnbdev_help                      Show help for all console scripts\nnbdev_install                   Install Quarto and the current library\nnbdev_install_hooks             Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks\nnbdev_install_quarto            Install latest Quarto on macOS or Linux, prints instructions for Windows\nnbdev_merge                     Git merge driver for notebooks\nnbdev_migrate                   Convert all markdown and notebook files in `path` from v1 to v2\nnbdev_new                       Create an nbdev project.\nnbdev_prepare                   Export, test, and clean notebooks, and render README if needed\nnbdev_preview                   Preview docs locally\nnbdev_proc_nbs                  Process notebooks in `path` for docs rendering\nnbdev_pypi                      Create and upload Python package to PyPI\nnbdev_readme                    None\nnbdev_release_both              Release both conda and PyPI packages\nnbdev_release_gh                Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git`\nnbdev_release_git               Tag and create a release in GitHub for the current version\nnbdev_sidebar                   Create sidebar.yml\nnbdev_test                      Test in parallel notebooks matching `path`, passing along `flags`\nnbdev_trust                     Trust notebooks matching `fname`\nnbdev_update                    Propagate change in modules matching `fname` to notebooks that created them"
  },
  {
    "objectID": "tutorial.html#important-files",
    "href": "tutorial.html#important-files",
    "title": "NBDev Tutorial",
    "section": "Important Files",
    "text": "Important Files\n\nsettings.ini - You can setup the project config directly from here like description, repository name, author name, etc.\nindex.ipynb - This is the most important notebook. The documentation generated from this notebook becomes part of your ReadMe, PiP, and Conda Description page. This will be the homepage for your documentation.\n00_core.ipynb - This is an example notebook in which you can write the functions for your library. As pre-written in the notebook, this gets exported to core.py python module. You can add more such notebooks, not necessarily with naming conventions like 00_ but Jeremy Howard suggests using this as this then acts like a journal showing the developer’s thought process."
  },
  {
    "objectID": "tutorial.html#directives",
    "href": "tutorial.html#directives",
    "title": "NBDev Tutorial",
    "section": "Directives",
    "text": "Directives\n\n#|default_exp <name>: Name of the module where cells with the #|export directive will be exported by default.\n#| export: Exports the items in the cell into the generated module and documentation.\n#| hide: Hides the code cell from the generated module as well as documentation. Used this in the import statements that need not be part of the generated module.\nIf you don’t pass any directive to the cell, that will be part of the documentation but not of the generated module.\n#|echo: <true|false>: Toggles the visibility of code cell in the documentation. Used this to hide the code cell that embedded the Youtube page in the documentation.\n#| output: <true|false|asis>: Toggles the visibility of the output from the code cell in the documentation. Used this to hide the print statements output from being part of the documentation\n#| filter_stream <space separated list of keywords>: Hides the keywords from the output of the code cell. Used this to hide the irritating warnings printed from the code cell when using the sklearn library.\n\nMany more useful directives are available, refer to the documentation for more."
  },
  {
    "objectID": "tutorial.html#extra-features",
    "href": "tutorial.html#extra-features",
    "title": "NBDev Tutorial",
    "section": "Extra Features",
    "text": "Extra Features\n\nNBDev supports most of the Quarto features. One of them I’ve used in my documentation is the mermaid flowchart which is very simple to make from a notebook. Refer to Quarto diagrams documentation to use other types of charts as part of your documentation.\nNBdev supports equations (using Quarto). You can include math in your notebook’s documentation using $$. Example: \\[\\sum_{i=1}^{k+1}i\\]\nUseful Jupyter extensions:\n\nCollapsible headings: This lets you fold and unfold each section in your notebook, based on its markdown headings.\nTOC2: This adds a table of contents to your notebooks, which you can navigate either with the Navigate menu item it adds to your notebooks or the TOC sidebar it adds. These can be modified and/or hidden using its settings.\n\nIf you already have a project, then you can simply migrate it to nbdev using the library built by Novetta.\n\nI haven’t explored this library yet, just adding this for information"
  },
  {
    "objectID": "tutorial.html#issues-i-faced-while-running-for-the-first-time",
    "href": "tutorial.html#issues-i-faced-while-running-for-the-first-time",
    "title": "NBDev Tutorial",
    "section": "Issues I faced while running for the first time",
    "text": "Issues I faced while running for the first time\n\nIn the NBDev documentation, it was not written to create an account on Pip and Conda registration page.\nsettings.ini by default doesn’t create variables for the conda environment which I had to figure out on my own. Manually add conda_user variable to the config. This name can be either your username or the name of the organization. Like FastAI uses fastai.\nI was using miniconda and didn’t know that I have to install anaconda client for doing the login. Found the solution from the resolved issue in nbdev repository\nWhen you run nbdev_release_both it updates the config and bumps the version number. There is some problem with the updated config, that leads to issues in deploying the docs to GitHub pages. To avoid this, don’t upload the updated config, instead, upload the old config with the bumped version number. This is a hacky solution, more investigation needs to be done to identify the exact issue."
  },
  {
    "objectID": "tutorial.html#references",
    "href": "tutorial.html#references",
    "title": "NBDev Tutorial",
    "section": "References",
    "text": "References\n\nNBDev Documentation\nNBDev 2.0 Tutorial by Jeremy Howard\nI like notebooks, video by Jeremy Howard\nMermaid flowchart"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "Documentation",
    "section": "",
    "text": "Visual overview of how the pipeline looks like."
  },
  {
    "objectID": "core.html#utility-functions",
    "href": "core.html#utility-functions",
    "title": "Documentation",
    "section": "Utility Functions",
    "text": "Utility Functions\n\nsource\n\ncompute_mean_and_covariance\n\n compute_mean_and_covariance (embdedding:numpy.ndarray,\n                              labels:numpy.ndarray)\n\nComputes class-specific means and a shared covariance matrix.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nembdedding\nndarray\n(n_sample, n_dim) n_sample - sample size of training set, n_dim - dimension of the embedding\n\n\nlabels\nndarray\n(n_sample, ) n_sample - sample size of training set\n\n\nReturns\nTuple\nMean of dimension (n_dim, ) and Covariance matrix of dimension(n_dim, n_dim)\n\n\n\n\nsource\n\n\ncompute_mahalanobis_distance\n\n compute_mahalanobis_distance (embdedding:numpy.ndarray,\n                               means:numpy.ndarray,\n                               covariance:numpy.ndarray)\n\nComputes Mahalanobis distance between the input and the fitted Guassians. The Mahalanobis distance (Mahalanobis, 1936) is defined as\n\\[distance(x, mu, sigma) = sqrt((x-\\mu)^T \\sigma^{-1} (x-\\mu))\\]\nwhere x is a vector, mu is the mean vector for a Gaussian, and sigma is the covariance matrix. We compute the distance for all examples in embdedding, and across all classes in means.\nNote that this function technically computes the squared Mahalanobis distance\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nembdedding\nndarray\nEmbdedding of dimension (n_sample, n_dim)\n\n\nmeans\nndarray\nA matrix of size (num_classes, n_dim), where the ith row corresponds to the mean of the fitted Gaussian distribution for the i-th class.\n\n\ncovariance\nndarray\nThe shared covariance matrix of the size (n_dim, n_dim)\n\n\nReturns\nndarray\nA matrix of size (n_sample, n_class) where the (i, j) element corresponds to the Mahalanobis distance between i-th sample to the j-th class Gaussian."
  },
  {
    "objectID": "core.html#ood-metric-computation-class",
    "href": "core.html#ood-metric-computation-class",
    "title": "Documentation",
    "section": "OOD Metric Computation Class",
    "text": "OOD Metric Computation Class\n\nsource\n\nOODMetric\n\n OODMetric (train_embdedding:numpy.ndarray, train_labels:numpy.ndarray)\n\nOOD Metric Class that calculates the OOD scores for a batch of input embeddings. Initialises the class by fitting the class conditional gaussian using training data and the class independent gaussian using training data.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ntrain_embdedding\nndarray\nAn array of size (n_sample, n_dim) where n_sample is the sample size of training set, n_dim is the dimension of the embedding.\n\n\ntrain_labels\nndarray\nAn array of size (n_train_sample, )\n\n\n\n\nsource\n\n\nOODMetric.compute_rmd\n\n OODMetric.compute_rmd (embdedding:numpy.ndarray)\n\nThis function computes the OOD score using the mahalanobis distance\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nembdedding\nndarray\nAn array of size (n_sample, n_dim), where n_sample is the sample size of the test set, and n_dim is the size of the embeddings.\n\n\nReturns\nndarray\nAn array of size (n_sample, ) where the ith element corresponds to the ood score of the ith data point."
  },
  {
    "objectID": "core.html#example",
    "href": "core.html#example",
    "title": "Documentation",
    "section": "Example",
    "text": "Example\nHere is an example where we generate 1000 samples having a 1024 dimensional embedding belonging to 10 clusters. Using the samples from last 5 cluster as test embeddings or ood embeddings and rest used as train embeddings\n\nn_samples = 1000\nn_centers = 10\nn_features = 1024\n\nx, y = make_blobs(n_samples=n_samples, n_features=n_features, centers=n_centers, random_state=0)\n\n\ntrain_embedding = x[np.where(y < (n_centers - 5))]\ntrain_labels = y[np.where(y < (n_centers - 5))]\n\ntest_embedding = x[np.where(y >= (n_centers - 5))]\ntest_labels = y[np.where(y >= (n_centers - 5))]\n\n\ntsne = TSNE(n_components=2).fit_transform(x)\n\nx_train_tsne = tsne[np.where(y < (n_centers - 5))]\nx_test_tsne = tsne[np.where(y >= (n_centers - 5))]\n\nplt.scatter(x_train_tsne[:, 0], x_train_tsne[:, 1], marker=\"o\", c=train_labels)\nplt.scatter(x_test_tsne[:, 0], x_test_tsne[:, 1], marker=\"+\", c=\"red\")\n\n\n\n\n<matplotlib.collections.PathCollection>\n\n\n\n\n\n\ntest_eq(type(train_embedding), np.ndarray) # check that embeddings are a numpy array\ntest_eq(type(train_labels), np.ndarray) # check that labels are numpy array\ntest_eq(train_labels.dtype, int) # check that labels are integers only\ntest_eq(train_labels.ndim, 1) # check that labels is one dimensional\ntest_eq(train_embedding.shape[0], train_labels.shape[0]) # check n_samples are same\n\n\nood = OODMetric(train_embedding, train_labels)\n\n\ntest_eq(ood.means.shape[0], len(np.unique(train_labels))) # for each unique class, we should get one mean embedding\ntest_eq(ood.means.shape[1], train_embedding.shape[1]) # size of mean vector should be the same of the size of embedding\n\ntest_eq(ood.covariance.shape[0], train_embedding.shape[1]) # covariance matrix should be of size n_dim, n_dim\ntest_eq(ood.covariance.shape[1], train_embedding.shape[1])\n\ntest_eq(ood.means_bg.shape[0], 1)\ntest_eq(ood.means_bg.shape[1], train_embedding.shape[1])\n\ntest_eq(ood.covariance_bg.shape[0], train_embedding.shape[1])\ntest_eq(ood.covariance_bg.shape[1], train_embedding.shape[1])\n\n\n# testing on the train embedding itself\nin_distribution_rmd = ood.compute_rmd(train_embedding)\n\n\nood_rmd = ood.compute_rmd(test_embedding)\n\nBy looking at the scores, we can get an idea of setting the threshold for classifying any datapoint as out of distribution. Below histogram shows a clear idea of what OOD Relative Mahalanobis distance look like.\n\nplt.hist([in_distribution_rmd, ood_rmd], label=[\"In Distribution\", \"OOD\"])\nplt.legend()\nplt.show()\n\n\n\n\n\ntest_eq(ood_rmd.shape[0], test_embedding.shape[0])\ntest_eq(ood_rmd.ndim, 1)"
  }
]